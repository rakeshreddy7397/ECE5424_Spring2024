{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "znIuRY7TjWgY",
        "ExecuteTime": {
          "end_time": "2024-04-29T17:23:04.760138Z",
          "start_time": "2024-04-29T17:23:02.860087Z"
        }
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "import torchvision.transforms as T\n",
        "\n",
        "\n",
        "class ClothingDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transforms):\n",
        "        self.root = root\n",
        "        self.transforms = transforms\n",
        "        # load all image files, sorting them to ensure that they are aligned.\n",
        "        self.imgs = list(sorted(os.listdir(os.path.join(root, \"png_images/IMAGES\"))))\n",
        "        self.masks = list(sorted(os.listdir(os.path.join(root, \"png_masks/MASKS\"))))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # load images and masks\n",
        "        img_path = os.path.join(self.root, \"png_images/IMAGES\", self.imgs[idx])\n",
        "        mask_path = os.path.join(self.root, \"png_masks/MASKS\",self.masks[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\") # grey-scale\n",
        "\n",
        "        # transform = T.RandomHorizontalFlip(p=0.5)\n",
        "        randomize=1 if torch.rand(1)>=0.5 else 0\n",
        "        if randomize==1:\n",
        "          transform = T.RandomHorizontalFlip(p=randomize)\n",
        "          img=transform(img)\n",
        "          mask=transform(mask)\n",
        "        mask = np.array(mask)\n",
        "        # instances are encoded as different colors\n",
        "        obj_ids = np.unique(mask)\n",
        "        if len(obj_ids)==1:\n",
        "            return\n",
        "        # first id is the background, so remove it\n",
        "        obj_ids = obj_ids[1:]\n",
        "\n",
        "        # split the color-encoded mask into a set of binary masks.\n",
        "        masks = mask == obj_ids[:, None, None]\n",
        "\n",
        "        # get bounding box coordinates for each mask\n",
        "        num_objs = len(obj_ids)\n",
        "        boxes = []\n",
        "        for i in range(num_objs):\n",
        "            pos = np.nonzero(masks[i])\n",
        "            xmin = np.min(pos[1])\n",
        "            xmax = np.max(pos[1])\n",
        "            ymin = np.min(pos[0])\n",
        "            ymax = np.max(pos[0])\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "        def extract_masks(holistic_mask):\n",
        "            unique_pixels = np.unique(holistic_mask)\n",
        "            masker = []\n",
        "            for pixel_value in unique_pixels:\n",
        "                binary_mask = (holistic_mask == pixel_value).astype(np.uint8)\n",
        "                masker.append(binary_mask)\n",
        "            return masker\n",
        "        masks = extract_masks(mask)\n",
        "        # if len(boxes)==0:\n",
        "        #   boxes.append([1,1,1,1])\n",
        "\n",
        "        # convert everything into a torch.Tensor\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        # there is only one class\n",
        "        # labels = torch.ones((num_objs,), dtype=torch.int64)\n",
        "        # labels = torch.zeros((58,), dtype=torch.int64)\n",
        "        labels=[]\n",
        "        for i in obj_ids:\n",
        "          # print(i)\n",
        "          labels.append(i)\n",
        "        labels=torch.as_tensor(labels, dtype=torch.int64)\n",
        "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
        "\n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"masks\"] = masks\n",
        "        target[\"image_id\"] = image_id\n",
        "\n",
        "\n",
        "        if self.transforms is not None:\n",
        "          img = self.transforms(img)\n",
        "        return img, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4FUlBRwXbs5"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')  # Change directory to the root of your Google Drive\n",
        "os.listdir('.')  # Lists the files in the current directory"
      ],
      "metadata": {
        "id": "J_NADbbtqah9",
        "ExecuteTime": {
          "end_time": "2024-04-29T17:29:59.350410Z",
          "start_time": "2024-04-29T17:29:59.342075Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "img = Image.open(\"/content/drive/My Drive/Colab Notebooks/png_masks/MASKS/seg_0001.png\").convert(\"L\")\n",
        "img_tensor = T.PILToTensor()(img)\n",
        "img_tensor.shape\n",
        "# img_tensor.unique()\n",
        "# m=get_transform(True)\n",
        "# print(typer)"
      ],
      "metadata": {
        "id": "lUYoUG1pMQGi",
        "ExecuteTime": {
          "end_time": "2024-04-29T17:23:09.470039Z",
          "start_time": "2024-04-29T17:23:09.443162Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UcMjEkuBjgoW"
      },
      "outputs": [],
      "source": [
        "#-----------------IGNORE---------------------------------------------\n",
        "\n",
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# load a model pre-trained on COCO\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "# replace the classifier with a new one, that has\n",
        "# num_classes which is user-defined\n",
        "num_classes = 58  # 1 class (person) + background\n",
        "# get number of input features for the classifier\n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "# replace the pre-trained head with a new one\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU3mDl4ljpSt"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
        "\n",
        "\n",
        "def get_model_instance_segmentation(num_classes):\n",
        "    # load an instance segmentation model pre-trained on COCO\n",
        "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "\n",
        "    # get number of input features for the classifier\n",
        "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "    # replace the pre-trained head with a new one\n",
        "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    # now get the number of input features for the mask classifier\n",
        "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
        "    hidden_layer = 128\n",
        "    # and replace the mask predictor with a new one\n",
        "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
        "                                                       hidden_layer,\n",
        "                                                       num_classes)\n",
        "    # print(model)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model_instance_segmentation(num_classes=58)\n",
        "# model=torchvision.models.detection.maskrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "# model=torchvision.models.detection.rpn\n",
        "print(model)"
      ],
      "metadata": {
        "id": "PSjNvb4-sPpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4MiUVu8jt1_"
      },
      "outputs": [],
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "def get_transform():\n",
        "    transforms = []\n",
        "    transforms.append(T.PILToTensor())\n",
        "    transforms.append(T.ConvertImageDtype(torch.float))\n",
        "    # if train:\n",
        "    #     transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    # transforms.append(T.Resize((height, width)))\n",
        "    return T.Compose(transforms)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, utils\n",
        "# def collate_fn(batch):\n",
        "#     return tuple(zip(*batch))\n",
        "def collate_fn(batch):\n",
        "    batch = [data for data in batch if data is not None]\n",
        "    # Your remaining collate logic here\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "dataset = ClothingDataset('/content/drive/My Drive/Colab Notebooks', transforms=get_transform())\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        " dataset, batch_size=2, shuffle=True,collate_fn=collate_fn)\n",
        "# For Training\n",
        "images,targets = next(iter(data_loader))\n",
        "images = list(image for image in images)\n",
        "targets = [{k: v for k, v in t.items()} for t in targets]\n",
        "output = model(images,targets)   # Returns losses and detections\n",
        "# For inference\n",
        "model.eval()\n",
        "x = [torch.rand(3, 300, 400), torch.rand(3, 500, 400)]\n",
        "predictions = model(x)           # Returns predictions"
      ],
      "metadata": {
        "id": "i0Zy0_2nRe0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_dict_reduced = reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "# train on the GPU or on the CPU, if a GPU is not available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# our dataset has two classes only - background and person\n",
        "num_classes = 59\n",
        "dataset = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform())\n",
        "dataset_test = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform())\n",
        "\n",
        "# split the dataset into train and test sets\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "print(len(dataset))\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2,collate_fn=collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=2,collate_fn=collate_fn)\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "# # and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "# optimizer=torch.optim.Adam(model.parameters(), lr=0.003, betas=(0.9, 0.9), eps=1)# and a learning rate scheduler\n",
        "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "# let's train it for 10 epochs\n",
        "num_epochs = 3\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "  lr_scheduler.step()\n",
        "  # evaluate(model, data_loader_test, device=device)\n"
      ],
      "metadata": {
        "id": "aM2z4BJGb5_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bITpDdOrj3EL"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq):\n",
        "    model.train()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    metric_logger.add_meter('lr', SmoothedValue(window_size=1, fmt='{value:.6f}'))\n",
        "    header = 'Epoch: [{}]'.format(epoch)\n",
        "\n",
        "    for images, targets in metric_logger.log_every(data_loader, print_freq, header):\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "\n",
        "        losses = sum(loss for loss in loss_dict.values())\n",
        "        loss_dict_reduced = reduce_dict(loss_dict)\n",
        "        losses_reduced = sum(loss for loss in loss_dict_reduced.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        losses.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        metric_logger.update(loss=losses_reduced, **loss_dict_reduced)\n",
        "        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n",
        "\n",
        "# train on the GPU or on the CPU, if a GPU is not available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "# our dataset has two classes only - background and person\n",
        "num_classes = 59\n",
        "# dataset = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform(train=True))\n",
        "dataset_test = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform(),train=False)\n",
        "\n",
        "# split the dataset into train and test sets\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True, num_workers=2,collate_fn=collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1, shuffle=False, num_workers=2,collate_fn=collate_fn)\n",
        "\n",
        "# get the model using our helper function\n",
        "model = get_model_instance_segmentation(num_classes)\n",
        "\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "# and a learning rate scheduler\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "\n",
        "# let's train it for 10 epochs\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "  lr_scheduler.step()\n",
        "  # evaluate(model, data_loader_test, device=device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3tydRKk24sh"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device=torch.device('cpu')\n",
        "def calculate_iou(box1, box2):\n",
        "    \"\"\"\n",
        "    Calculate the Intersection over Union (IoU) between two bounding boxes.\n",
        "\n",
        "    Arguments:\n",
        "    - box1 (tuple or list): C noordinates of the first bounding box in the format (x1, y1, x2, y2).\n",
        "    - box2 (tuple or list): Coordinates of the second bounding box in the format (x1, y1, x2, y2).\n",
        "\n",
        "    Returns:\n",
        "    - iou (float): Intersection over Union (IoU) between the two bounding boxes.\n",
        "    \"\"\"\n",
        "    x1, y1, x2, y2 = box1\n",
        "    x1_, y1_, x2_, y2_ = box2\n",
        "\n",
        "    # Calculate the coordinates of the intersection rectangle\n",
        "    inter_x1 = max(x1, x1_)\n",
        "    inter_y1 = max(y1, y1_)\n",
        "    inter_x2 = min(x2, x2_)\n",
        "    inter_y2 = min(y2, y2_)\n",
        "\n",
        "    # Calculate the area of intersection rectangle\n",
        "    inter_area = max(0, inter_x2 - inter_x1 + 1) * max(0, inter_y2 - inter_y1 + 1)\n",
        "\n",
        "    # Calculate the area of both bounding boxes\n",
        "    box1_area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "    box2_area = (x2_ - x1_ + 1) * (y2_ - y1_ + 1)\n",
        "\n",
        "    # Calculate the IoU\n",
        "    iou = inter_area / float(box1_area + box2_area - inter_area)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_bounding_boxes(predictions, target):\n",
        "    iou_threshold = 0.5  # IoU threshold for considering a prediction as correct\n",
        "\n",
        "    total_predictions = len(predictions)\n",
        "    # print(total_predictions,\"total\")\n",
        "    total_ground_truth = len(target[\"boxes\"])\n",
        "    correct_predictions = 0\n",
        "    ground_truthpred=0\n",
        "    total_actual_predictions=0\n",
        "\n",
        "\n",
        "    for pred_box, pred_score, pred_label in predictions:\n",
        "        best_iou = 0\n",
        "        best_match = None\n",
        "        # ground_truthpred=0\n",
        "\n",
        "        for gt_box, gt_label in zip(target[\"boxes\"], target[\"labels\"]):\n",
        "            # print(gt_box,gt_label)\n",
        "            iou = calculate_iou(pred_box, gt_box)\n",
        "\n",
        "\n",
        "            if iou > best_iou and iou > iou_threshold and pred_label == gt_label:\n",
        "                best_iou = iou\n",
        "                best_match = (gt_box, gt_label)\n",
        "            elif iou>0.6 and pred_label!=gt_label:\n",
        "                total_actual_predictions+=1\n",
        "\n",
        "\n",
        "        if best_match is not None:\n",
        "          correct_predictions += 1\n",
        "\n",
        "\n",
        "\n",
        "    precision = correct_predictions / total_actual_predictions if total_actual_predictions > 0 else 0\n",
        "    recall = correct_predictions / total_ground_truth if total_ground_truth > 0 else 0\n",
        "\n",
        "    if precision + recall > 0:\n",
        "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1_score = 0\n",
        "\n",
        "    return precision, recall, f1_score\n",
        "\n",
        "\n",
        "\n",
        "def evaluate(model, data_loader, device):\n",
        "    model.eval()\n",
        "    metric_logger = MetricLogger(delimiter=\"  \")\n",
        "    header = \"Test:\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets in metric_logger.log_every(data_loader, 100, header):\n",
        "            images = [img.to(device) for img in images]  # Move images to the correct device\n",
        "            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "            model_time = time.time()\n",
        "            outputs = model(images)\n",
        "            model_time = time.time() - model_time\n",
        "\n",
        "            metric_logger.update(model_time=model_time)\n",
        "\n",
        "            # Evaluate bounding boxes\n",
        "            for output, target in zip(outputs, targets):\n",
        "                pred_boxes = output[\"boxes\"].cpu().numpy()\n",
        "                pred_scores = output[\"scores\"].cpu().numpy()\n",
        "                pred_labels = output[\"labels\"].cpu().numpy()\n",
        "\n",
        "                true_boxes = target[\"boxes\"].cpu().numpy()\n",
        "                true_labels = target[\"labels\"].cpu().numpy()\n",
        "\n",
        "                unique_pred_labels = set(pred_labels)  # Get unique predicted labels\n",
        "\n",
        "                predictions = []\n",
        "                for label in unique_pred_labels:\n",
        "                    label_indices = np.where(pred_labels == label)[0]\n",
        "                    max_score_index = np.argmax(pred_scores[label_indices])\n",
        "                    max_score_box = pred_boxes[label_indices[max_score_index]]\n",
        "                    max_score = pred_scores[label_indices[max_score_index]]\n",
        "                    predictions.append((max_score_box, max_score, label))\n",
        "\n",
        "                target = {\"boxes\": true_boxes, \"labels\": true_labels}\n",
        "            # for output, target in zip(outputs, targets):\n",
        "            #     pred_boxes = output[\"boxes\"].cpu().numpy()\n",
        "            #     pred_scores = output[\"scores\"].cpu().numpy()\n",
        "            #     pred_labels = output[\"labels\"].cpu().numpy()\n",
        "\n",
        "            #     true_boxes = target[\"boxes\"].cpu().numpy()\n",
        "            #     true_labels = target[\"labels\"].cpu().numpy()\n",
        "\n",
        "                # predictions = list(zip(pred_boxes, pred_scores, pred_labels))\n",
        "                target = {\"boxes\": true_boxes, \"labels\": true_labels}\n",
        "\n",
        "                precision, recall, f1_score = evaluate_bounding_boxes(predictions, target)\n",
        "                # print(recall)\n",
        "\n",
        "                metric_logger.update(recall=recall,precision=precision)\n",
        "                    # precision=precision, recall=recall, f1_score=f1_score)\n",
        "    # recall_meter = metric_logger.meters['recall']\n",
        "    # recall_avg = sum(recall_meter)/ len(recall_meter) if len(recall_meter)>0 else 0.0\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(\"DONE (t={:.2f}s).\".format(metric_logger.meters['model_time'].global_avg))\n",
        "    print(\"Avg Precision: {:.4f}\".format(metric_logger.meters['precision'].global_avg))\n",
        "    print(\"Avg Recall: {:.4f}\".format(metric_logger.meters['recall'].global_avg))\n",
        "    # print(\"F1 Score: {:.4f}\".format(metric_logger.meters['f1_score'].global_avg))\n",
        "    # print(\"Recall avg: {:.4f}\".format(recall_avg))\n",
        "\n",
        "evaluate(model, data_loader_test, device=device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NtohfUiqk7hL"
      },
      "outputs": [],
      "source": [
        "#only showing top 8 predictions for each picture\n",
        "dataset = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform(train=True))\n",
        "\n",
        "dataset_test = ClothingDataset('/content/drive/MyDrive/Clothing DataSet', get_transform(train=False))\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
        "\n",
        "img, _ = dataset_test[14]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "img = img.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model([img])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxYljnZrul6a"
      },
      "outputs": [],
      "source": [
        "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsul9v9cuqnv"
      },
      "outputs": [],
      "source": [
        "prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXuBQ1fFuvwo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def plot_prediction(image, prediction):\n",
        "    fig, ax = plt.subplots(1)\n",
        "    ax.imshow(Image.fromarray(image.mul(255).permute(1, 2, 0).byte().cpu().numpy()))\n",
        "    boxes = prediction[0]['boxes'].cpu().numpy()\n",
        "    labels = prediction[0]['labels'].cpu().numpy()\n",
        "    scores = prediction[0]['scores'].cpu().numpy()\n",
        "    labname=['null',\n",
        "    'accessories',\n",
        "    'bag',\n",
        "    'belt',\n",
        "    'blazer',\n",
        "    'blouse',\n",
        "    'bodysuit',\n",
        "    'boots',\n",
        "    'bra',\n",
        "    'bracelet',\n",
        "    'cape',\n",
        "    'cardigan',\n",
        "    'clogs',\n",
        "    'coat',\n",
        "    'dress',\n",
        "    'earrings',\n",
        "    'flats',\n",
        "    'glasses',\n",
        "    'gloves',\n",
        "    'hair',\n",
        "    'hat',\n",
        "    'heels',\n",
        "    'hoodie',\n",
        "    'intimate',\n",
        "    'jacket',\n",
        "    'jeans',\n",
        "    'jumper',\n",
        "    'leggings',\n",
        "    'loafers',\n",
        "    'necklace',\n",
        "    'panties',\n",
        "    'pants',\n",
        "    'pumps',\n",
        "    'purse',\n",
        "    'ring',\n",
        "    'romper',\n",
        "    'sandals',\n",
        "    'scarf',\n",
        "    'shirt',\n",
        "    'shoes',\n",
        "    'shorts',\n",
        "    'skin',\n",
        "    'skirt',\n",
        "    'sneakers',\n",
        "    'socks',\n",
        "    'stockings',\n",
        "    'suit',\n",
        "    'sunglasses',\n",
        "    'sweater',\n",
        "    'sweatshirt',\n",
        "    'swimwear',\n",
        "    't-shirt',\n",
        "    'tie',\n",
        "    'tights',\n",
        "    'top',\n",
        "    'vest',\n",
        "    'wallet',\n",
        "    'watch',\n",
        "    'wedges']\n",
        "    label_data = {}\n",
        "    for box, label, score in zip(boxes, labels, scores):\n",
        "        if label not in label_data or score > label_data[label]['score'] and label!=0:\n",
        "            label_data[label] = {'score': score, 'box': box}\n",
        "\n",
        "    unique_labels = list(label_data.keys())\n",
        "    highest_scores = [label_data[label]['score'] for label in unique_labels]\n",
        "    corresponding_boxes = [label_data[label]['box'] for label in unique_labels]\n",
        "    counter=0\n",
        "    for label, score, box in zip(unique_labels, highest_scores, corresponding_boxes):\n",
        "      if score > 0.0and counter<=8:  # Filter boxes based on score threshold\n",
        "            # Get box coordinates\n",
        "            xmin, ymin, xmax, ymax = box\n",
        "\n",
        "\n",
        "            # Create a rectangle patch\n",
        "            rect = patches.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n",
        "                                     linewidth=1, edgecolor='r', facecolor='none')\n",
        "\n",
        "            # Add the patch to the plot\n",
        "            ax.add_patch(rect)\n",
        "\n",
        "            # Add label and score text\n",
        "            label_text = f\"Label: {labname[label.item()]}\"\n",
        "            score_text = f\"Score: {score:.2f}\"\n",
        "            ax.text(xmin, ymin, label_text, fontsize=8, color='r')\n",
        "            ax.text(xmin, ymin + 15, score_text, fontsize=8, color='r')\n",
        "            counter+=1\n",
        "            print(labname[label.item()])\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "plot_prediction(img.cpu(), prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rA1KYGOqLx4V"
      },
      "outputs": [],
      "source": [
        "img, _ = dataset_test[16]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "img = img.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model([img])\n",
        "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().cpu().numpy())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdYJj4U2u10o"
      },
      "outputs": [],
      "source": [
        "plot_prediction(img.cpu(), prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4YMsVhvQGhQ_"
      },
      "outputs": [],
      "source": [
        "img, _ = dataset_test[22]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "img = img.to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    prediction = model([img])\n",
        "Image.fromarray(img.mul(255).permute(1, 2, 0).byte().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcAnYK7UsWHK"
      },
      "outputs": [],
      "source": [
        "plot_prediction(img.cpu(), prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zevbfLVsZXx"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "mask_tensor = prediction[0][\"masks\"].cpu().numpy()  # Convert tensor to numpy array\n",
        "mask_index = 0 # Index of the mask to print\n",
        "\n",
        "mask_array = np.squeeze(mask_tensor[mask_index])  # Get the selected mask array and remove unnecessary dimensions\n",
        "mask_image = Image.fromarray((mask_array * 255).astype(np.uint8))\n",
        "\n",
        "mask_image.save(\"mask_image.png\")\n",
        "mask_image\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming prediction[0][\"masks\"] is a tensor\n",
        "mask_tensor = prediction[0][\"masks\"].cpu().numpy()  # Convert tensor to numpy array\n",
        "\n",
        "# Create a blank canvas with the same dimensions as the masks\n",
        "num_masks = mask_tensor.shape[0]  # Number of masks\n",
        "height, width = mask_tensor.shape[-2:]  # Height and width of each mask\n",
        "canvas = np.zeros((height, width))\n",
        "\n",
        "# Overlay each mask on the canvas\n",
        "for mask_index in range(num_masks):\n",
        "    mask_array = np.squeeze(mask_tensor[mask_index])  # Get the mask array\n",
        "    canvas += mask_array\n",
        "\n",
        "# Normalize the values of the canvas to [0, 1]\n",
        "canvas = np.clip(canvas, 0, 1)\n",
        "\n",
        "# Display the canvas\n",
        "plt.imshow(canvas, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yeGhH6sl4gJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "\n",
        "# Assuming prediction[0][\"masks\"] is a tensor\n",
        "mask_tensor = prediction[0][\"masks\"].cpu().numpy()  # Convert tensor to numpy array\n",
        "\n",
        "# Create a blank canvas with the same dimensions as the masks\n",
        "num_masks = mask_tensor.shape[0]  # Number of masks\n",
        "height, width = mask_tensor.shape[-2:]  # Height and width of each mask\n",
        "canvas = np.zeros((height, width))\n",
        "\n",
        "# Overlay each mask on the canvas\n",
        "for mask_index in range(num_masks):\n",
        "    mask_array = np.squeeze(mask_tensor[mask_index])  # Get the mask array\n",
        "    canvas += mask_array\n",
        "\n",
        "# Normalize the values of the canvas to [0, 1]\n",
        "canvas = np.clip(canvas, 0, 1)\n",
        "\n",
        "# Convert the grayscale mask to RGB\n",
        "mask_rgb = cm.inferno(canvas)  # Apply a color map (e.g., inferno) to the grayscale image\n",
        "\n",
        "# Display the RGB mask\n",
        "plt.imshow(mask_rgb)\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "57AsYdg_4jxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SF_UbD1O5h7x"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "name": "python3",
      "language": "python"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}